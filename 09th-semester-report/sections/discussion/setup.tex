\section{Setup}

In this section, different aspects of how the experimental setup was made will be discussed.

\paragraph*{Test cases based on time or iterations:} In this work, the test cases are executed based on time rather than runs, where runs is chosen in other studies\cite*[]{Pereira2017,Koedijk2022diff,Georgiou2020}. One work running test cases based on time, is the work by Sestoft\cite*[]{sestoft2013microbenchmarks}, where $0.25$s is chosen to avoid problems with the virtual machine and the clock resolution. Another argument for time made by Sestoft\cite*[]{sestoft2013microbenchmarks} is when considering test cases of different sizes, where 100 milion runs might be too time consuming for larger test cases. In this work the argument is because of E3, where the test cases has to run for one minute for E3 to detect the test case. A side effect of running based on time is that the different test cases will most likely not run for an equal amount. This potential issue is addressed in this work by running Cochran's one all test cases, and ensuring all test cases has enough measurements. 

% \paragraph*{A C\# implementation of the framework:} In other works,  

% \paragraph*{SQL:}

\paragraph*{Test cases:} In this work, the test cases used were chosen based on what is generally used in research\cite*[]{Koedijk2022diff, greenland2016statistical}. The argument for using such test cases is to make this work more comparable to ensure everything is implemented correctly. Questionmarks can however be made with regards to how well a such test case represents a real life application. Because of this, it could have been interesting to test the different measuring instruments on larger applications, where could be a potential future work. In this work, all test cases are implemented in C\#, as the focus is not to compare energy consumption of any specific language, but rather to compare the measuring instruments. It could however have been interesting to test an even wider range of test cases, also including different language. This could be interesting as when comparing the different measuring instruments in \cref*{sec:iterations} some overall patterns could be observed, but there were always exceptions, like how RAPL only in some cases reported a higher energy consumption compared to IPG and LHM. Additional test cases could help finding patters if for example RAPL was better/worse when measuring certain kinds of operations. This is however a task for a future work.  
%% not unsafe
%% small test cases
%% only c#

\paragraph*{Background processes:} In this work, different processes were disabled, in order to limit their effect on the measurements. These processes includes the ones presented in \cref*{tab:disabled_proc} and Windows update. One thing to note here, is how no background processes are disabled for Linux, as we were unable to find any processes which made sense to disable. For Windows, eight background processes were located and stopped upon startup for the DUT, but for both OSs it can be argued more time could have been spend trying to limit the activity of background processes. This was based on the expectation that a fresh install of both OSs would mean they would have a limited amount of background processes, which is a subject for a future work. 

\paragraph*{Temperature:} For the temperature, there was an expectation that when the CPU reached some temperature, an effect would be observable on the results. This did however not happen, as was discussed in \cref{subsec:TempBat}. The reason for this, as was also mention in \cref{subsec:TempBat}, was most likely due to the test cases never stressing the CPU enough to reach temperatures beyond 65 degrees. As a result of this, no temperature limits were set when running the experiments. It could however have been interesting to see what impact temperatures above 65 degrees had on the results. Given the temperatures never increased above 65 for the test cases used, a stress test could have been used for the experiment instead. The stress test would be expected to bring the CPU to higher temperatures, as it will bring the load of the CPU to 100\%, and since the effect of a overheated CPU would be expected to be similar for all test cases, it would be fine that the stress test is used instead of the test cases. This is however a subject for a future work.

\paragraph*{Battery:} Given some issues on the surface devices as discussed in \cref{subsec:TempBat}, the battery limit were set between $40-80$\%. Within these limits, no visible effect of the battery limit could be find. The expectation for this experiment covered in \cref{subsec:TempBat} was to find some lower limit, where the energy consumption would change. This would occur as the DUT would enter a power saving mode, when some battery percentage is reached. This power saving mode would most likely cause the OS to stop some background process and under clocking the CPU. When a CPU is under clocked, the test case would run less samples during a measurement. The energy consumption of one samples when the DUT is on power saving mode is expected to be different compared to when the DUT is not in power saving mode, but this is a subject for future work. For both surface devices, the power mode is set to maximum, where it could have been interesting to see how the results would change if the power saving mode would be different, this is however a subject for future works. 

%% power mode