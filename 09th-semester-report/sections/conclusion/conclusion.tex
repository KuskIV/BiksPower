In the following, we will summarize the answers to the research question presented in \cref{ch:introduction}. These research questions were made based on observations of how most existing works use the Linux tool RAPL, where our work's main goal was to compare other existing software-based measuring instruments for Windows against RAPL. All measurements were also compared to a hardware measurement tool, serving as a ground truth. To conduct the experiments we created a framework in C\# which could automatically run the measuring instruments and test cases on both Windows and Linux. The framework would run on the DUT's startup, where background processes would be stopped and WIFI disabled to limit intererence in the measurements. When measuring the energy consumption, test cases would execute for one minute, while the framework would start and stop the different measuring instruments in a round robin fashion using R3-validation, where between each test case the WIFI so the measurements could be uploaded to an SQL database. The framework also had a set number of runs it would execute before restarting the DUT and then continuing to iterate over the four different software-based measuring instruments and the hardware-based measuring instrument as well as the 5 different test cases. Cochran's formula was then used to calculate how many measurements we needed to ensure our desired margin of error of 3\% and confidence level of 95\% on our results. This framework ran on three different DUTs, where one of them was a workstation without a battery and the remaining two were laptops. One of the laptops had a MAXIM chip which was claimed to improve the measurement capabilities of E3. This claim was however not reflected in the results. To allow for comparison between DUTs we used dynamic energy consumption, which allowed us to isolate the energy consumption for the test case only, rather than from the entire CPU. Then analyzing our results the correlation of the measurements is calculated to discover if they follow the same trends when measuring energy consumption.




% In this section our work is concluded by summarizing the answers to the research questions presented in \cref{ch:introduction} and then forming and overall conclusions to our works main goal of comparing different measuring instruments in order to explore how the measuring instruments on Windows performs in comparison with our ground truth, and the software-based solution most commonly utilized in the literature, which is RAPL. 

%The first research question, \textbf{RQ1}, was about how to measure the energy consumption the different DUTs and OSs in way that made them comparable. 
% \paragraph*{}
% \cref{sec:experimental_setup} presents the methods used in this work, where our measurement methodology and our framework are described. Dynamic energy is also introduced, which allowed us to isolate the energy consumption of the test case, rather than the entire CPU. The notion of dynamic energy was used throughout the results to compare the energy consumption of the test cases with minimum noise from the OSs and across different DUTs. 

%The third research question, \textbf{RQ3}, was about how the measurements compare on the two OSs. 
\paragraph*{}
In experiment \#1 we observed a higher or similar standard deviation for the measurement on Windows compared to Linux. We also saw that Windows in the majority of cases had a higher actual and dynamic energy consumption compared to Linux, which did not align with our expectations. It was also observed that the energy consumption of the idle test case was lower than we expected. Because of this, a second experiment was conducted, where the C-states were disabled on the CPU of the workstation. In this experiment, the energy consumption in the idle test case increased, and the dynamic energy consumption of Windows decreased, reflecting our expectations from experiment \#1.

%%% CORROLATION exp 2
%The fourth research question, \textbf{RQ4}, was about how the DUTs compare. 
\paragraph*{}
Between the different DUTs, all measuring instruments reported a higher energy consumption for the workstation. For the laptops, the Surface Pro 4 had a higher energy consumption compared to the Surface Book, reported by all measuring instruments, only with a few exceptions. One difference between the laptops was the MAXIM chip on the Surface Book, which supposedly should make E3 more accurate. The E3 measurement for the Surface Book does have a $.02$ and $.01$ higher correlation with IPG and LHM respectively, which could mean that E3 is more accurate on the Surface Book if IPG and LHM are accurate. The Surface Book had a lower correlation between the RAPL measurements and the other software-based measuring instruments than the Surface Pro 4, it is however unclear why.

%The second research question, \textbf{RQ2}, about how do measuring instruments compared
\paragraph*{}
For the measuring instruments, we found that LHM and IPG are very similar in terms of measurements as well as being highly correlated with each other. RAPL in the majority of cases measured a lower energy consumption than LHM and IPG and it also had a lower standard deviation, with a few exceptions. E3 in most cases report an energy consumption between RAPL and LHM/IPG. The primary issue with E3 includes requirements of how the DUT should have a battery and the inability to start and stop the measuring instrument as wished, making the E3 more tedious to utilize for our purpose. In experiment \#1, the highest correlation with the clamp on the same OS as the software-based measuring instrument was LHM and IPG with a $.01$ difference. Compared to this, RAPL had a slightly lower correlation, which suggests that LHM and IPG are more accurate than RAPL. In experiment \#2 RAPL had the highest correlation with the clamp, indicating it is more accurate for our test cases. It should however be noted that both IPG and LHM are also highly correlated, while E3 has a low to moderate correlation. The higher correlation between LHM and IPG suggests similarities in terms of how they access energy consumption from the CPU. When comparing IPG and LHM, both had issues, where IPG crashed on some DUTs and LHM had a lower sampling rate. Opposed to this there is RAPL, which overall seems like a more integrated measuring instrument.
