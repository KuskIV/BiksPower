\subsection{R3 Validation}\label[subsec]{subsec:exp_r3}

In this work, an adapted version of R3 validation is used, based on the work by Bokhari et al.\cite[]{Bokhari2020r3}. The data presented in this chapter is only based on three measuring instruments, as some problems occurred while measuring using both E3 and the Clamp. When looking at the results for the different DUTs, similar observations can be made, which is why the results for only the workstation can be observed in \cref{fig:PowerKomplett_HardwareMonitor_Cores_R3_dynamic_energy_without_outliers_Win32NT_avg_watts}. The results for the other DUT's can be found in \cref{app:r3_validation}. 


\input{tabels/experiment_results/R3/dynamic_energy/PowerKomplett/Win32NT/without_outliers/Cores/HardwareMonitor.tex}

\paragraph{Expectations:} R3 validation was chosen in this work, because Bokhari et al.\cite[]{Bokhari2020r3} observed the order of which the test cases were executed in, mattered. This was argued to be the case because the state of the DUT changed over time, where different background processes executed at different times and would use different amount of processor power. This could evoke garbage collection, which would impact the measured energy consumption. Because of this, it was deemed unfair to execute the test cases in the same order, which resulted in the R3 way of switching the order upon a restart. The work by Bokhari et al. was however done on an android phone, where our work is on Windows and Linux, where less background processes are expected to interfere with the results. Because of this, the impact of R3 is expected to be limited.

\paragraph{Problems:} During the experiments regarding the impact of R3 validation, E3 had some issues, and were thus excluded from the experiments. This was however concluded to be okay, as a conclusion could be made based only on iterating over Clamp, LHM and Intel Power Gadget. Another issue occurred because of the problems with Intel Power Gadget, as covered in \cref{subsec:TempBat}, which caused the DUT's to crash. The crashes occurred especially for the Surface Book, less for the Surface Pro 4, and almost never for the workstation, which is why the workstation was chosen. Because the Surface Book crashed, most of the restarts of this DUT would be a result of the background script, rather than the framework. This meant the distribution of which measurement instrument started, was not equal.

\paragraph{Conclusion:} When considering the results for the workstation, it can be seen in \cref{fig:PowerKomplett_HardwareMonitor_Cores_R3_dynamic_energy_without_outliers_Win32NT_avg_watts}. Here the energy consumption measured by LHM can be seen, where the measurements are the average dynamic energy in watts. On the y-axis, labels describe what test case is measured, and which measuring instrument was the first to run. This means, for each test case, there are three plots, since three measuring instruments was used on the workstation on Windows. What can be observed in \cref{fig:PowerKomplett_HardwareMonitor_Cores_R3_dynamic_energy_without_outliers_Win32NT_avg_watts} is a smaller impact than expected, where the R3 validation can be concluded to have no impact on the measurements at all. This means the assumption about less background processes in Windows is true, at least on a fresh install of Windows. Because of this, R3 validation will be disregarded, and not used anymore through the experiments. In addition to this, the E3 experiments not executed yet, will be run independently, without iterating over all measuring instruments.
