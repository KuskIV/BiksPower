% Has anyone else tried to compare energy measurement tools?

\section{Similar Work}\label[section]{sec:similar_work}

When considering what existing work aims to compare the accuracies of different energy measuring instruments there exists a few. One is the work by Hackenberg et al.\cite[]{hackenberg2013} which aims to find which instrument measures the energy consumption of a system best. This is done by measuring using Intel's RAPL, AMD's APM and comparing them against both AC and DC measuring while running a sequence of synthetic code designed to provide a controllable workload. Hackenberg et al. found AC to be the most accurate one, as $95\%$ and $96\%$ of samples vary with less than 2W in the two tests conducted.

Another work comparing different measurement instruments is the work by Jagroep et al.\cite[]{Jagroep2015}. This work evaluates different measurement instruments through a series of experiments on both idle and full load scenarios where the estimated energy consumption is compared to the actual consumption as reported by hardware measurements. Here it is noted that despite having access to roughly the same data the results can differ significantly between the different measurement instruments. The study includes 14 different measurement instruments, picked based on four criteria. These include: at least a beta version should be available, it should be able to sample at least once per second, it should run on Linux or Windows and it should be compatible with their hardware. They do however have some issues when trying to download and set up most of the measuring instruments, but those that do work are run on either Windows or Linux on the same sample code.

%% This work used watts up meter Jagroep2015

Instead of comparing measuring instruments, work aiming to compare the energy consumption of different language constructs within the same language also exists. On such work is by Lindholt et al.\cite[]{Lindholt2022}, where a comparison was made of four groups of language constructs within C\#, including concurrency, casting parameter mechanisms and lambda expressions. This is achieved using 150 micro benchmarks, where a further analysis is conducted on each of the constructs in order to understand the results. Based on the findings, 68 macro benchmarks are created in order to test the observations on a larger scale and to see how the constructs work in combination with each other. This could also be the work by Rasmussen et al.\cite[]{Rasmussen2021}, where a study by Kumar et al\cite[]{Kumar2017} made in Java is analyzed, and reproduced in C\# to see how the results compare in a new language. The study includes different primitive types like selections, collections, objects inheritance and exceptions, and when comparing the results it is concluded there can be drastic differences between Java and C\# in certain situations. Another study by \cite[]{Theilmann2022} looks into two different implementations of a microservice architecture, one with a shared database connection or one with a database connection per service. These implementations are analyzed w.r.t. the energy consumption and compared to a monolithic architecture. This study was done on two similar implementations on C\# and Java, where the energy consumption is compared, and a significant difference can be found, both when comparing languages, but also between the type of database connection.

Other studies also exists, considering even more different languages. In the work by Pereira et al.\cite[]{Pereira2017} 27 of the most popular languages are compared, where the languages are compared with each other, but also in groups considering compiled, interpreted and virtual machine languages or object oriented, functional and imperative languages. The languages are tested across ten different test cases testing different loads, and the results show how the picked language can have a huge impact on the energy consumption of the program, and that a faster program is not always greener.

\input{sections/related_work/Fahad.tex}