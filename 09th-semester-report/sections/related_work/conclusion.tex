\section{Key takeaways}\label[section]{sec:rw_key_takeaways}

%Eventuelt Split op i fysisk måling eller software related works så det ikke bliver en så langt.

In this section, the key takeaways from the knowledge gathered in the \cref*{ch:related_work} are presented. These are the major aspects of previous works that are considered or implemented in some way in this work. 

In \cref*{sec:rw_diff_measuring_instruments} the idea of comparing different measuring instruments as Japgroep et al.\cite*{Jagroep2015} did was presented. However, in that work, only two measuring instruments could be set up to conduct measurements, and those two are old and no longer maintained.\todo{this may need source} Therefore, they are not used in this work. However, the idea of comparing different measuring instruments is the essence of this work as well. A measuring instrument used in multiple other works is Intel's RAPL\cite*{RAPL_in_action,hackenberg2013,fahad2019comparative} and is as such relevant to include in this work. However, as shown by Khan et al.\cite*{RAPL_in_action} Intel's RAPL performs differently on different Intel CPU architectures and while shown to be a viable alternative to hardware-based measurements in many cases Fahad et al.\cite*{fahad2019comparative} and Hackenberg et al.\cite*{hackenberg2013} showed that in some cases it was not very accurate compared to the hardware-based measuring instrument. Therefore a hardware-based measuring instrument to be used as a ground truth is also essential to this work. 

Another aspect presented in the work by Fahad et al.\cite*{fahad2019comparative} is the concept of dynamic energy consumption. This is also implemented in this work to enable comparison between our hardware-based measurements and software-based measurements.\newline

% Fahad
% Hackenberg
% Khan

% Add terminology alert
In \cref*{sec:rw_measureing_methodology_setup} different frameworks and other aspects of methodology were presented. First of all, some of the contributions from Mancebo et al. \cite*{GarciaFEETINGS} are also incorporated to some extent in this work. Specifically, some of the terminology defined in the GSMO. However, some aspects are irrelevant to our work and will not be used. Furthermore, some additional terminology is also needed. The terminology can be seen in \cref*{tab:TerminologyAlert}. The two other components are the methodological component and the technological components, both of which are not used.

In the work by Sestoft\cite*{sestoft2013microbenchmarks} several things to consider when running benchmarks are presented. For example how the JIT compilation can affect the execution time of benchmarks and how garbage collection can also be an uncontrollable factor. Furthermore, a list of potential pitfalls is presented, which are considered when implementing the framework used in this work. 

Bokhari et al.\cite*{Bokhari2020r3} came up with \textit{R3-VALIDATION} to avoid system software states changing from restarting the DUT and to generally improve the fairness of running several different test cases. This approach has also been implemented in this work.

Finally, it was noted by Dongarra et al.\cite*{Dongarra2012} that when comparing results gathered from different DUTs or measuring instruments it is useful to have the same sampling rate across the setups. This will also be implemented if possible within the limits of the different measuring instruments used in this work.


% Mancebo
% Sestoft
% Bokhari