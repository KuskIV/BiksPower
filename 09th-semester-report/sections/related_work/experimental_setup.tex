% When running the experiments, what code is best to test a language

\section{Experimental Setup}

When running experiments on energy consumption of hardware, it is not straight forward, as many factors can impact the experiment. This is covered in the work by Sestof\cite*[]{sestoft2013microbenchmarks}, where a framework to measure execution time of microbenchmarks is created in a iteratively manner where different pitfalls are uncovered. The reason why energy consumption measurements are not straight forward is because of a large number of factors which has been introduced in complex modern systems. This is especially clear on managed execution platforms like the Common Language Infrastructure (.Net) from Microsoft or the Java Virtual Machine (JVM) where software in an intermediate from is compiled to real machine code at runtime by just-in-time (JIT) compilation, which affects the execution time fore a few reasons. One thing is w.r.t the start-up overhead of the JIT or the adaptive optimization of JIT compilation. What top optimization does is locating code executed only a few times, and code executed a lot, which results in a prioritization, where a lot of time is used to generate optimized code for code executed many times, an quickly generated code is made when the code is executed only a few times. The JIT compiler also avoids using a lot of time on code analysis, which can result in cases where the generated code works well on simpler contexts, and in more complex contexts, the performance is not as good. Another factor the programmer cannot control is the automatic memory management, which may decide to run the garbage collection during the experiments, resulting in unreliable results. The same can be said for the operating system, processors and memory management systems.

In the process of creating the framwork for measuring execution time, Sestof\cite*[]{sestoft2013microbenchmarks} uses a \texttt{multiply} method which performs 20  floating point multiplications, an integer bitwise "and" and a conversion from a 32-bit int to a 64-bit double. During the first phases, one observation is how when running the experiments for many iterations, the execution time drops to zero. This happens because the JIT compiler observes the result of the method is not used for anything, resulting in it skipping the method entirely. When measuring the runtime of the experiment, only measuring one execution is deemed too little as the results vary too much. This should rather be multiple runs, and then looking at the average runtime and the standard deviation. These multiple runs are in this study deemed to be until the execution time exceeds $0.25$ seconds, as this is long enough to avoid problems with virtual machine startup and clock resolution. In the end, som additional pitfalls are noted, including:

\begin{itemize}
    \item Shut down as many background services as possible, as this can impact performance
    \item The generation of logging and debug messages can use more than 90\% of execution time, so this should be disabled
    \item An IDE uses a lot of CPU time and cause slower execution time because of debugging code, so do not execute through IDEs
    \item Disable power saving schemes so the CPU does not reduce its speed during benchmark runs.
    \item Compile with relevant optimization options so the generated bytecode does not include code to accommodate debugging
    \item Different implementations of .NET and JVM has different characteristics and has different garbage collectors
    \item Different CPU brands, versions (like desktop or mobile) and hardware (like ram) has different characteristics
    \item Reflect on results, and if they look slow/fast something might have been overlooked.
\end{itemize}

%% benchmarking c# for energy consumption Ã¸rsted nielsen


Bokhari et al\cite{Bokhari2020r3} found that when running benchmarks comparing different variants of the same program on Android systems, noise had an impact on the results. This was due to noise coming from several uncontrollable factors. Firstly the systems software states meaning the background processes which could not be fully controlled during the execution of the experiments. Secondly the memory consumption of the Android system and background processes. Thirdly the battery voltage, because even though the system was fully charged at the starting point as well as the remaining voltage level after. To solve this they propose a method called \textit{R3-VALIDATION} which is a rotated round-robin approach to running the program variants, which ensures more fair execution conditions. In this approach the variants (A, B, C) are rotated as follows: setup, ABC, ABC, setup, BCA, BCA, setup, CAB, CAB. Where the setup phase is a restart, initialization and recharge of the system. They achieved more consistent system states from this approach.